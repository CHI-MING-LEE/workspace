{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on 2019/05/01\n",
    "\n",
    "Topic: ResNet using Keras\n",
    "\n",
    "Ref: \n",
    "1. https://blog.csdn.net/qq_25491201/article/details/78405549#%E6%95%B4%E4%B8%AA%E4%BB%A3%E7%A0%81%E7%9A%84%E6%B5%81%E7%A8%8B%E5%A6%82%E4%B8%8B\n",
    "2. https://blog.csdn.net/u013093426/article/details/81166751\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T15:04:54.098666Z",
     "start_time": "2019-05-02T15:04:51.862281Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, concatenate, \\\n",
    "    Activation, ZeroPadding2D\n",
    "from keras.layers import add, Flatten\n",
    "from keras.utils import plot_model\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Conv Block 1 (Conv + BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T15:04:57.314273Z",
     "start_time": "2019-05-02T15:04:57.307706Z"
    }
   },
   "outputs": [],
   "source": [
    "def Conv2d_BN(x, nb_filter, kernel_size, strides=(1, 1), padding='same', name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "\n",
    "    x = Conv2D(nb_filter, kernel_size, padding=padding, strides=strides, activation='relu', name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=3, name=bn_name)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Basic Indentity Block (Residual Block)\n",
    "<img src=\"./ResidualBlock.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T15:14:08.518401Z",
     "start_time": "2019-05-02T15:14:08.510746Z"
    }
   },
   "outputs": [],
   "source": [
    "def identity_Block(inpt, nb_filter, kernel_size, strides=(1, 1), with_conv_shortcut=False):\n",
    "    x = Conv2d_BN(inpt, nb_filter=nb_filter, kernel_size=kernel_size, strides=strides, padding='same')\n",
    "    x = Conv2D(nb_filter=nb_filter, kernel_size=kernel_size, padding='same')(x)\n",
    "    # x = Conv2d_BN(x, nb_filter=nb_filter, kernel_size=kernel_size, padding='same')\n",
    "    if with_conv_shortcut:\n",
    "        # block的input與output維度不同就需要轉換\n",
    "        # padding='same' -> W/S (利用stride降維)\n",
    "        # https://medium.com/@chih.sheng.huang821/%E5%8D%B7%E7%A9%8D%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF-convolutional-neural-network-cnn-%E5%8D%B7%E7%A9%8D%E8%A8%88%E7%AE%97%E4%B8%AD%E7%9A%84%E6%AD%A5%E4%BC%90-stride-%E5%92%8C%E5%A1%AB%E5%85%85-padding-94449e638e82\n",
    "        shortcut = Conv2d_BN(inpt, nb_filter=nb_filter, strides=strides, kernel_size=kernel_size)\n",
    "        x = add([x, shortcut])\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        return x\n",
    "    else:\n",
    "        x = add([x, inpt])\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottleneck Block (1x1 conv,  >= 50 ResNet)\n",
    "- 作者在研究更深层次(层数大于50)的网络的时候，使用了Bottleneck这个网络结构。我觉得作者可能是参考了goolenet里面的Inception结构。我们可以看到在Bottleneck中，第一个1x1的卷积层用来在降低纬度(用来降低运算复杂度)，而后一个的1x1的卷积层则用来增加纬度，使其保持与原来的输入具有相同的纬度。(从而可以进行恒等映射)。\n",
    "<img src=\"./BottleneckBlock.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T15:14:11.486149Z",
     "start_time": "2019-05-02T15:14:11.478652Z"
    }
   },
   "outputs": [],
   "source": [
    "def bottleneck_Block(inpt, nb_filters, strides=(1,1), with_conv_shortcut=False):\n",
    "    k1, k2, k3 = nb_filters\n",
    "    x = Conv2d_BN(inpt, nb_filter=k1, kernel_size=1, strides=strides, padding='same') # 1x1 conv\n",
    "    x = Conv2d_BN(x, nb_filter=k2, kernel_size=3, padding='same')\n",
    "    x = Conv2D(nb_filter=k3, kernel_size=1, padding='same')(x)  # 1x1 conv\n",
    "    # x = Conv2d_BN(x, nb_filter=k3, kernel_size=1, padding='same')  \n",
    "    if with_conv_shortcut:\n",
    "        shortcut = Conv2d_BN(inpt, nb_filter=k3, strides=strides, kernel_size=1)\n",
    "        x = add([x, shortcut])\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        return x\n",
    "    else:\n",
    "        x = add([x, inpt])\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T15:14:14.191434Z",
     "start_time": "2019-05-02T15:14:14.175792Z"
    }
   },
   "outputs": [],
   "source": [
    "def resnet_34(width, height ,channel, classes):\n",
    "    inpt = Input(shape=(width, height, channel))\n",
    "    x = ZeroPadding2D((3, 3))(inpt)\n",
    "\n",
    "    #conv1\n",
    "    x = Conv2d_BN(x, nb_filter=64, kernel_size=(7, 7), strides=(2, 2), padding='valid')\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    #conv2_x\n",
    "    x = identity_Block(x, nb_filter=64, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=64, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=64, kernel_size=(3, 3))\n",
    "\n",
    "    #conv3_x\n",
    "    x = identity_Block(x, nb_filter=128, kernel_size=(3, 3), strides=(2, 2), with_conv_shortcut=True)\n",
    "    x = identity_Block(x, nb_filter=128, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=128, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=128, kernel_size=(3, 3))\n",
    "\n",
    "    #conv4_x\n",
    "    x = identity_Block(x, nb_filter=256, kernel_size=(3, 3), strides=(2, 2), with_conv_shortcut=True)\n",
    "    x = identity_Block(x, nb_filter=256, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=256, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=256, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=256, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=256, kernel_size=(3, 3))\n",
    "\n",
    "    #conv5_x\n",
    "    x = identity_Block(x, nb_filter=512, kernel_size=(3, 3), strides=(2, 2), with_conv_shortcut=True)\n",
    "    x = identity_Block(x, nb_filter=512, kernel_size=(3, 3))\n",
    "    x = identity_Block(x, nb_filter=512, kernel_size=(3, 3))\n",
    "    x = AveragePooling2D(pool_size=(7, 7))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inpt, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T15:16:35.172706Z",
     "start_time": "2019-05-02T15:16:29.578914Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rossleecooloh/.pyenv/versions/3.6.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), padding=\"same\", filters=64)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/rossleecooloh/.pyenv/versions/3.6.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), padding=\"same\", filters=128)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/rossleecooloh/.pyenv/versions/3.6.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), padding=\"same\", filters=256)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/rossleecooloh/.pyenv/versions/3.6.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), padding=\"same\", filters=512)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 230, 230, 3)  0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 112, 112, 64) 9472        zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 112, 112, 64) 256         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 56, 56, 64)   0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 56, 56, 64)   36928       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 56, 56, 64)   256         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 56, 56, 64)   36928       batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 56, 56, 64)   0           conv2d_77[0][0]                  \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 56, 56, 64)   0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 56, 56, 64)   256         activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 56, 56, 64)   36928       batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 56, 56, 64)   256         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 56, 56, 64)   36928       batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 56, 56, 64)   0           conv2d_79[0][0]                  \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 56, 56, 64)   0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 56, 56, 64)   256         activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 56, 56, 64)   36928       batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 56, 56, 64)   256         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 56, 56, 64)   36928       batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 56, 56, 64)   0           conv2d_81[0][0]                  \n",
      "                                                                 batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 56, 56, 64)   0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 56, 56, 64)   256         activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 28, 28, 128)  73856       batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 28, 28, 128)  512         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 28, 28, 128)  73856       batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 28, 28, 128)  147584      batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 28, 28, 128)  512         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 28, 28, 128)  0           conv2d_83[0][0]                  \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 28, 28, 128)  0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 28, 28, 128)  512         activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 28, 28, 128)  147584      batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 28, 28, 128)  512         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 28, 28, 128)  147584      batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 28, 28, 128)  0           conv2d_86[0][0]                  \n",
      "                                                                 batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 28, 28, 128)  0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 28, 28, 128)  512         activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 28, 28, 128)  147584      batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 28, 28, 128)  512         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 28, 28, 128)  147584      batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 28, 28, 128)  0           conv2d_88[0][0]                  \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 28, 28, 128)  0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 28, 28, 128)  512         activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 28, 28, 128)  147584      batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 28, 28, 128)  512         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 28, 28, 128)  147584      batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 28, 28, 128)  0           conv2d_90[0][0]                  \n",
      "                                                                 batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 28, 28, 128)  0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 28, 28, 128)  512         activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 14, 14, 256)  295168      batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 14, 14, 256)  1024        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 14, 14, 256)  295168      batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 14, 14, 256)  590080      batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 14, 14, 256)  1024        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 14, 14, 256)  0           conv2d_92[0][0]                  \n",
      "                                                                 batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 256)  0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 14, 14, 256)  1024        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 14, 14, 256)  590080      batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 14, 14, 256)  1024        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 14, 14, 256)  590080      batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 14, 14, 256)  0           conv2d_95[0][0]                  \n",
      "                                                                 batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 14, 14, 256)  0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 14, 14, 256)  1024        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 14, 14, 256)  590080      batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 14, 14, 256)  1024        conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 14, 14, 256)  590080      batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 14, 14, 256)  0           conv2d_97[0][0]                  \n",
      "                                                                 batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 14, 14, 256)  0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 14, 14, 256)  1024        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 14, 14, 256)  590080      batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 14, 14, 256)  1024        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 14, 14, 256)  590080      batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 14, 14, 256)  0           conv2d_99[0][0]                  \n",
      "                                                                 batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 14, 14, 256)  0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 14, 14, 256)  1024        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 14, 14, 256)  590080      batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 14, 14, 256)  1024        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 14, 14, 256)  590080      batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 14, 14, 256)  0           conv2d_101[0][0]                 \n",
      "                                                                 batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 14, 14, 256)  0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 14, 14, 256)  1024        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 14, 14, 256)  590080      batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 14, 14, 256)  1024        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 14, 14, 256)  590080      batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 14, 14, 256)  0           conv2d_103[0][0]                 \n",
      "                                                                 batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 14, 14, 256)  0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 14, 14, 256)  1024        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 7, 7, 512)    1180160     batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 7, 7, 512)    2048        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 7, 7, 512)    1180160     batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 7, 7, 512)    2359808     batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 7, 7, 512)    2048        conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 7, 7, 512)    0           conv2d_105[0][0]                 \n",
      "                                                                 batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 512)    0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 7, 7, 512)    2048        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 7, 7, 512)    2359808     batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 7, 7, 512)    2048        conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 7, 7, 512)    2359808     batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 7, 7, 512)    0           conv2d_108[0][0]                 \n",
      "                                                                 batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 7, 7, 512)    2048        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 7, 7, 512)    2359808     batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 7, 7, 512)    2048        conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 7, 7, 512)    2359808     batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 7, 7, 512)    0           conv2d_110[0][0]                 \n",
      "                                                                 batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 7, 7, 512)    2048        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 512)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 512)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           5130        flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,691,594\n",
      "Trainable params: 22,674,570\n",
      "Non-trainable params: 17,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_34(224, 224, 3, 10).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_50(width,height,channel,classes):\n",
    "    inpt = Input(shape=(width, height, channel))\n",
    "    x = ZeroPadding2D((3, 3))(inpt)\n",
    "    x = Conv2d_BN(x, nb_filter=64, kernel_size=(7, 7), strides=(2, 2), padding='valid')\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    #conv2_x\n",
    "    x = bottleneck_Block(x, nb_filters=[64,64,256],strides=(1,1),with_conv_shortcut=True)\n",
    "    x = bottleneck_Block(x, nb_filters=[64,64,256])\n",
    "    x = bottleneck_Block(x, nb_filters=[64,64,256])\n",
    "\n",
    "    #conv3_x\n",
    "    x = bottleneck_Block(x, nb_filters=[128, 128, 512],strides=(2,2),with_conv_shortcut=True)\n",
    "    x = bottleneck_Block(x, nb_filters=[128, 128, 512])\n",
    "    x = bottleneck_Block(x, nb_filters=[128, 128, 512])\n",
    "    x = bottleneck_Block(x, nb_filters=[128, 128, 512])\n",
    "\n",
    "    #conv4_x\n",
    "    x = bottleneck_Block(x, nb_filters=[256, 256, 1024],strides=(2,2),with_conv_shortcut=True)\n",
    "    x = bottleneck_Block(x, nb_filters=[256, 256, 1024])\n",
    "    x = bottleneck_Block(x, nb_filters=[256, 256, 1024])\n",
    "    x = bottleneck_Block(x, nb_filters=[256, 256, 1024])\n",
    "    x = bottleneck_Block(x, nb_filters=[256, 256, 1024])\n",
    "    x = bottleneck_Block(x, nb_filters=[256, 256, 1024])\n",
    "\n",
    "    #conv5_x\n",
    "    x = bottleneck_Block(x, nb_filters=[512, 512, 2048], strides=(2, 2), with_conv_shortcut=True)\n",
    "    x = bottleneck_Block(x, nb_filters=[512, 512, 2048])\n",
    "    x = bottleneck_Block(x, nb_filters=[512, 512, 2048])\n",
    "\n",
    "    x = AveragePooling2D(pool_size=(7, 7))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inpt, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_top2(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
    "\n",
    "\n",
    "def check_print():\n",
    "    # Create a Keras Model\n",
    "    model = resnet_50(IM_WIDTH,IM_HEIGHT,3,NB_CLASS)\n",
    "    model.summary()\n",
    "    # Save a PNG of the Model Build\n",
    "    plot_model(model, to_file='resnet.png')\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc',top_k_categorical_accuracy])\n",
    "    print 'Model Compiled'\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if os.path.exists('resnet_50.h5'):\n",
    "        model=load_model('resnet_50.h5')\n",
    "    else:\n",
    "        model=check_print()\n",
    "\n",
    "    model.fit_generator(train_generator,validation_data=vaild_generator,epochs=EPOCH,steps_per_epoch=train_generator.n/batch_size\n",
    "                        ,validation_steps=vaild_generator.n/batch_size)\n",
    "    model.save('resnet_50.h5')\n",
    "    loss,acc,top_acc=model.evaluate_generator(test_generator, steps=test_generator.n / batch_size)\n",
    "    print 'Test result:loss:%f,acc:%f,top_acc:%f' % (loss, acc, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
